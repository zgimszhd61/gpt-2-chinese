# GPT-2模型卡片

最后更新时间:2019年11月

受[模型报告的模型卡片(Mitchell等人)](https://arxiv.org/abs/1810.03993)的启发,我们在此提供一些关于我们发布的GPT-2模型系列的附加信息。

## 模型详情

该模型由OpenAI的研究人员开发,旨在帮助我们理解语言模型能力如何随着模型大小(参数数量)和非常大的互联网规模数据集(WebText)的增加而扩展。

### 模型日期

2019年2月,在2017年年底之前的数据上训练。

### 模型类型 

语言模型

### 模型版本

15亿参数:第四个也是最大的GPT-2版本。我们还发布了1.24亿、3.55亿和7.74亿参数的模型。

### 更多信息的论文或其他资源
[博客文章](https://openai.com/blog/better-language-models/)和[论文](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)

### 在哪里发送关于该模型的问题或评论
请使用此[Google表格](https://forms.gle/A7WBSbTY2EkKdroPA)

## 预期用途:

### 主要预期用途

这些模型的主要预期用户是*人工智能研究人员和从业人员*。

我们主要想象这些语言模型将被研究人员用来更好地理解大规模生成语言模型的行为、能力、偏差和约束。

### 次要用途

以下是我们认为可能的次要用途:

- **写作辅助**:语法辅助、自动补全(用于普通散文或代码)
- **创意写作和艺术**:探索创作性、虚构性文本的生成;辅助诗歌和其他文学艺术创作。
- **娱乐**:创作游戏、聊天机器人和有趣的生成内容。

### 超出范围的用例

由于像GPT-2这样的大规模语言模型无法区分事实与虚构,我们不支持需要生成的文本为真实的用例。

此外,像GPT-2这样的语言模型反映了它们所训练系统中固有的偏差,因此我们不建议在没有首先对预期用例的相关偏差进行研究的情况下,将它们部署到与人互动的系统中。我们发现774M和1.5B之间在性别、种族和宗教偏差探测方面没有统计学上的显著差异,这意味着所有版本的GPT-2在处理与人类属性相关的敏感用例时,应该以类似的谨慎程度来对待。

## 评估数据

### 数据集

该模型是在WebText上训练和评估的,WebText是由Reddit社交网络用户发布的4500万个链接的文本内容组成的数据集。WebText是由Reddit的外部链接衍生的数据组成的,不包含直接来自Reddit本身的数据。在生成数据集之前,我们使用了阻止列表,以确保我们不会从包含色情或其他令人反感内容的各种Reddit子版块中采样。

为了了解进入GPT-2的数据,我们[发布了](domains.txt)WebText中出现频率最高的1000个域名及其频率的列表。按量计算,WebText中排名前15的域名是:Google、Archive、Blogspot、GitHub、纽约时报、Wordpress、华盛顿邮报、Wikia、BBC、卫报、eBay、Pastebin、CNN、Yahoo!和赫芬顿邮报。

### 动机

WebText背后的动机是创建一个互联网规模的、异构的数据集,我们可以用它来测试大规模语言模型。WebText旨在用于研究目的,而不是生产目的。

### 警告和建议

由于GPT-2是一个互联网规模的语言模型,目前很难知道可以对其应用哪些严格的测试程序来完全了解其功能,以及它所训练的数据如何影响其广泛的输出。我们建议研究人员调查模型的这些方面并分享他们的研究结果。

此外,正如我们在讨论与模型潜在滥用相关的问题时所指出的,目前仍不清楚检测这些模型输出的长期动态是什么。我们进行了[内部自动化ML检测研究](https://github.com/openai/gpt-2-output-dataset/tree/master/detector),使用简单分类器、零次和微调方法。我们的微调检测器模型达到了大约95%的准确率。然而,没有一种检测方法是万能的;自动化ML检测、人工检测、人机协作和基于元数据的检测都是可以结合使用以获得更高置信度分类的方法。今天开发更好的检测方法将让我们对未来的模型有更好的直觉,并可以帮助我们提前了解检测方法是否最终会失效。